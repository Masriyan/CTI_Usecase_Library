# Prioritize CVE Remediation Using Exploit Intelligence

## Metadata
- **Use Case ID:** VI-UC001
- **Category:** Vulnerability Intelligence
- **Difficulty:** Intermediate
- **Estimated Time:** 2-3 hours
- **Last Updated:** 2025-12-30

## Description
Organizations face an overwhelming number of vulnerabilities across their infrastructure—often thousands of CVEs requiring remediation with limited resources. Traditional prioritization based solely on CVSS scores fails to account for real-world exploitation likelihood, threat actor interest, and environmental context. This disconnect leads to misallocated remediation efforts, leaving actively exploited vulnerabilities unpatched while teams focus on high-CVSS but low-risk issues.

This use case demonstrates how to integrate exploit intelligence—including exploit availability, active exploitation in the wild, threat actor campaigns, and environmental exposure—with vulnerability data to create risk-based prioritization that focuses remediation efforts on CVEs that pose actual threats to your organization.

## Objectives
By completing this use case, you will:
- Integrate multiple intelligence sources for comprehensive CVE risk assessment
- Identify CVEs with active exploitation or available public exploits
- Correlate vulnerability data with organizational asset criticality
- Calculate contextualized risk scores combining technical and threat factors
- Generate actionable remediation priority lists for vulnerability management teams
- Measure and optimize remediation effectiveness

## Prerequisites

### Data Sources
- **Vulnerability Scan Results** - Nessus, Qualys, Rapid7, Tenable
- **Asset Inventory** - CMDB with criticality ratings
- **Exploit Databases** - ExploitDB, Metasploit, Packet Storm
- **Threat Intelligence** - CISA KEV, VulnDB, threat feeds
- **EPSS Scores** - Exploit Prediction Scoring System data

### Tools & Platforms
- **Vulnerability Management Platform** - Tenable.io, Qualys VMDR, Rapid7 InsightVM
- **Threat Intelligence Platform** - Recorded Future, ThreatConnect, MISP
- **EPSS API** - FIRST.org Exploit Prediction Scoring
- **SIEM** - For correlation with exploitation attempts
- **Asset Management** - ServiceNow CMDB or similar

### Required Skills
- Vulnerability management fundamentals
- Understanding of CVSS scoring and limitations
- Threat intelligence analysis and correlation
- Risk assessment and prioritization methodologies
- Data analysis and Excel/Python for scoring models

### Access Requirements
- Read access to vulnerability scan results
- Access to asset inventory and criticality data
- Threat intelligence platform API access
- Ability to communicate priorities to IT operations

## Step-by-Step Workflow

### Step 1: Extract Vulnerability Data
**Objective:** Compile complete vulnerability inventory with baseline metadata

**Actions:**
1. Export vulnerability scan results from all scanners (Nessus, Qualys, etc.)
2. Normalize data to common schema (CVE, asset, CVSS, description)
3. Deduplicate vulnerabilities across multiple scan sources
4. Filter for patchable vulnerabilities (exclude end-of-life, accepted risks)
5. Document vulnerability counts by severity

**Example:**
```python
import pandas as pd

def extract_vulnerability_data(scan_results_files):
    """Extract and normalize vulnerability data from multiple sources"""
    all_vulns = []

    for scan_file in scan_results_files:
        df = pd.read_csv(scan_file)

        # Normalize to common schema
        normalized = df[['CVE', 'Host', 'IP', 'CVSS_Score', 'Plugin_Name', 'Description']]
        normalized.columns = ['cve', 'hostname', 'ip', 'cvss', 'title', 'description']

        all_vulns.append(normalized)

    # Combine and deduplicate
    combined = pd.concat(all_vulns, ignore_index=True)
    deduplicated = combined.drop_duplicates(subset=['cve', 'ip'])

    return deduplicated

vulns_df = extract_vulnerability_data(['nessus_scan.csv', 'qualys_scan.csv'])
print(f"Total unique vulnerabilities: {len(vulns_df)}")
```

**Output:** Normalized vulnerability dataset ready for enrichment

---

### Step 2: Enrich with Exploit Intelligence
**Objective:** Identify which CVEs have available exploits or active exploitation

**Actions:**
1. Query CISA KEV catalog for known exploited vulnerabilities
2. Check ExploitDB and Metasploit for public exploit availability
3. Query threat intelligence feeds for exploitation campaigns
4. Retrieve EPSS scores for exploitation probability
5. Flag CVEs with weaponized exploits vs. PoC code

**Example:**
```python
import requests

def enrich_with_exploit_intelligence(vulns_df):
    """Enrich CVEs with exploit and exploitation data"""

    # Get CISA KEV data
    kev_url = "https://www.cisa.gov/sites/default/files/feeds/known_exploited_vulnerabilities.json"
    kev_response = requests.get(kev_url)
    kev_cves = {v['cveID'] for v in kev_response.json()['vulnerabilities']}

    # Get EPSS scores
    cve_list = vulns_df['cve'].unique().tolist()
    epss_scores = get_epss_scores(cve_list)  # Custom function

    # Enrich dataframe
    vulns_df['in_cisa_kev'] = vulns_df['cve'].isin(kev_cves)
    vulns_df['epss_score'] = vulns_df['cve'].map(epss_scores)
    vulns_df['has_public_exploit'] = vulns_df['cve'].apply(check_exploit_db)

    return vulns_df

def check_exploit_db(cve):
    """Check if CVE has exploits in ExploitDB"""
    # Simplified - use ExploitDB API in production
    return False  # Placeholder

enriched_df = enrich_with_exploit_intelligence(vulns_df)
```

**Output:** Vulnerability data enriched with exploitation intelligence

---

### Step 3: Correlate with Asset Criticality
**Objective:** Understand business impact of each vulnerability

**Actions:**
1. Join vulnerability data with asset inventory/CMDB
2. Assign business criticality scores to each asset
3. Identify public-facing vs. internal assets
4. Document data classification (PII, financial, classified)
5. Map to business services and dependencies

**Example:**
```python
def correlate_asset_criticality(vulns_df, cmdb_df):
    """Add asset criticality context to vulnerabilities"""

    # Join with CMDB
    enriched = vulns_df.merge(
        cmdb_df[['ip', 'criticality', 'exposure', 'data_classification', 'business_service']],
        on='ip',
        how='left'
    )

    # Define criticality scores
    criticality_map = {
        'critical': 100,
        'high': 75,
        'medium': 50,
        'low': 25,
        'info': 10
    }

    enriched['criticality_score'] = enriched['criticality'].map(criticality_map).fillna(50)

    # Exposure multiplier
    enriched['exposure_multiplier'] = enriched['exposure'].apply(
        lambda x: 1.5 if x == 'external' else 1.0
    )

    return enriched
```

**Output:** Vulnerability data with business context

---

### Step 4: Calculate Contextual Risk Scores
**Objective:** Generate composite risk scores incorporating multiple factors

**Actions:**
1. Design risk scoring formula combining CVSS, EPSS, KEV status, asset criticality
2. Weight factors based on organizational risk tolerance
3. Calculate normalized risk scores (0-100 scale)
4. Validate scoring against known critical vulnerabilities
5. Document scoring methodology for stakeholders

**Example:**
```python
def calculate_risk_score(row):
    """Calculate contextualized vulnerability risk score"""

    # Base technical score (CVSS)
    technical_score = row['cvss'] * 10  # Normalize to 100

    # Exploit availability (0-30 points)
    exploit_score = 0
    if row['in_cisa_kev']:
        exploit_score = 30  # Actively exploited
    elif row['has_public_exploit']:
        exploit_score = 20  # Exploit available
    elif row['epss_score'] > 0.5:
        exploit_score = 15  # High exploitation probability

    # Asset criticality (0-25 points)
    asset_score = row['criticality_score'] / 4

    # Exposure (multiplier)
    exposure_mult = row['exposure_multiplier']

    # Calculate composite score
    composite = (technical_score * 0.4) + exploit_score + asset_score
    final_score = composite * exposure_mult

    return min(final_score, 100)  # Cap at 100

enriched_df['risk_score'] = enriched_df.apply(calculate_risk_score, axis=1)
```

**Output:** Risk-scored vulnerability list

---

### Step 5: Prioritize and Tier Remediation
**Objective:** Create tiered remediation plan with SLA recommendations

**Actions:**
1. Sort vulnerabilities by risk score (highest first)
2. Group into remediation tiers (Critical: 0-7 days, High: 8-30 days, etc.)
3. Consider remediation complexity and patch availability
4. Identify quick wins (high risk, easy remediation)
5. Generate remediation roadmap with timelines

**Example:**
```python
def tier_remediation(enriched_df):
    """Assign remediation tiers and SLAs"""

    def assign_tier(score):
        if score >= 80:
            return 'P1 - Critical (0-7 days)'
        elif score >= 60:
            return 'P2 - High (8-30 days)'
        elif score >= 40:
            return 'P3 - Medium (31-90 days)'
        else:
            return 'P4 - Low (91-180 days)'

    enriched_df['remediation_tier'] = enriched_df['risk_score'].apply(assign_tier)

    # Sort by priority
    prioritized = enriched_df.sort_values('risk_score', ascending=False)

    # Summary statistics
    tier_summary = prioritized['remediation_tier'].value_counts()

    return prioritized, tier_summary

prioritized_df, summary = tier_remediation(enriched_df)
```

**Output:** Prioritized remediation plan with SLAs

---

### Step 6: Identify Exploitation Attempts
**Objective:** Correlate prioritized CVEs with actual exploitation attempts

**Actions:**
1. Query SIEM/IDS logs for exploitation signatures
2. Search EDR for post-exploitation artifacts
3. Correlate web application firewall blocks with CVEs
4. Identify systems with both vulnerability AND exploitation attempts
5. Escalate confirmed exploitation to incident response

**Example:**
```sql
-- SIEM query to find exploitation attempts
SELECT
    v.cve,
    v.hostname,
    v.risk_score,
    COUNT(DISTINCT e.src_ip) as exploit_attempts,
    MAX(e.timestamp) as last_attempt
FROM prioritized_vulnerabilities v
JOIN ids_alerts e ON v.cve = e.cve_tag AND v.ip = e.dest_ip
WHERE e.timestamp > date_sub(now(), INTERVAL 30 DAY)
GROUP BY v.cve, v.hostname, v.risk_score
HAVING exploit_attempts > 0
ORDER BY v.risk_score DESC, exploit_attempts DESC
```

**Output:** High-risk CVEs with confirmed exploitation attempts

---

### Step 7: Generate Remediation Reports
**Objective:** Create actionable reports for vulnerability management teams

**Actions:**
1. Generate executive summary with key metrics
2. Create detailed remediation lists by tier
3. Produce asset owner-specific reports
4. Develop trend analysis (new vs. remediated vulnerabilities)
5. Include threat intelligence context for top risks

**Example:**
```python
def generate_remediation_report(prioritized_df):
    """Generate comprehensive remediation report"""

    report = {
        'executive_summary': {
            'total_vulnerabilities': len(prioritized_df),
            'critical_p1': len(prioritized_df[prioritized_df['remediation_tier'].str.contains('P1')]),
            'high_p2': len(prioritized_df[prioritized_df['remediation_tier'].str.contains('P2')]),
            'in_cisa_kev': len(prioritized_df[prioritized_df['in_cisa_kev']]),
            'with_public_exploits': len(prioritized_df[prioritized_df['has_public_exploit']]),
            'external_facing': len(prioritized_df[prioritized_df['exposure'] == 'external'])
        },
        'top_10_risks': prioritized_df.nlargest(10, 'risk_score')[[
            'cve', 'hostname', 'risk_score', 'cvss', 'in_cisa_kev',
            'criticality', 'exposure', 'remediation_tier'
        ]].to_dict('records'),
        'by_tier': prioritized_df.groupby('remediation_tier').size().to_dict(),
        'recommendations': generate_recommendations(prioritized_df)
    }

    return report

def generate_recommendations(df):
    """Generate contextualized recommendations"""
    recommendations = []

    if df['in_cisa_kev'].sum() > 0:
        recommendations.append(
            f"URGENT: {df['in_cisa_kev'].sum()} vulnerabilities from CISA KEV catalog "
            "are being actively exploited in the wild. Prioritize immediate remediation."
        )

    return recommendations
```

**Output:** Comprehensive remediation report

---

### Step 8: Track Remediation Progress
**Objective:** Monitor and measure remediation velocity and effectiveness

**Actions:**
1. Track remediation completion rates by tier
2. Measure time-to-remediation for each priority level
3. Monitor SLA compliance for remediation tiers
4. Identify bottlenecks in remediation process
5. Calculate risk reduction metrics

**Example:**
```python
def track_remediation_progress(initial_df, current_df):
    """Calculate remediation metrics"""

    initial_count = len(initial_df)
    current_count = len(current_df)
    remediated_count = initial_count - current_count

    metrics = {
        'total_remediated': remediated_count,
        'remediation_rate': (remediated_count / initial_count * 100) if initial_count > 0 else 0,
        'remaining_p1': len(current_df[current_df['remediation_tier'].str.contains('P1')]),
        'risk_reduction': initial_df['risk_score'].sum() - current_df['risk_score'].sum(),
        'avg_remediation_time_days': calculate_avg_remediation_time(),
        'sla_compliance': calculate_sla_compliance()
    }

    return metrics
```

**Output:** Remediation effectiveness metrics

---

### Step 9: Continuous Intelligence Integration
**Objective:** Maintain up-to-date exploit intelligence for ongoing prioritization

**Actions:**
1. Schedule daily CISA KEV updates
2. Monitor threat intelligence for new exploitation campaigns
3. Refresh EPSS scores weekly
4. Integrate with vulnerability scanner for automatic enrichment
5. Alert on new critical CVEs affecting environment

**Example:**
```python
# Automation schedule
automation_schedule = {
    "daily": [
        "update_cisa_kev_catalog",
        "refresh_epss_scores_for_new_cves",
        "scan_for_new_vulnerabilities",
        "generate_daily_priority_changes"
    ],
    "weekly": [
        "full_epss_refresh",
        "remediation_progress_report",
        "threat_intelligence_correlation"
    ],
    "monthly": [
        "scoring_model_validation",
        "sla_compliance_review",
        "executive_briefing"
    ]
}

def monitor_new_critical_cves():
    """Alert on new KEV additions affecting environment"""
    # Get latest KEV catalog
    latest_kev = fetch_cisa_kev()

    # Check against environment
    affected_assets = correlate_kev_with_assets(latest_kev, asset_inventory)

    if affected_assets:
        send_alert(
            f"URGENT: {len(affected_assets)} assets affected by new CISA KEV entries",
            affected_assets
        )
```

**Output:** Automated intelligence update pipeline

---

### Step 10: Optimize Prioritization Model
**Objective:** Continuously improve risk scoring based on outcomes

**Actions:**
1. Review false positives (high-scored vulnerabilities with low actual risk)
2. Analyze false negatives (low-scored vulnerabilities that were exploited)
3. Adjust scoring weights based on organizational experience
4. Incorporate feedback from IT operations on remediation difficulty
5. Validate model against industry benchmarks

**Example:**
```python
def optimize_scoring_model(historical_data):
    """Analyze and optimize risk scoring model"""

    # Analyze false positives
    false_positives = historical_data[
        (historical_data['risk_score'] > 70) &
        (historical_data['actual_exploitation'] == False) &
        (historical_data['business_impact'] == 'low')
    ]

    # Analyze false negatives
    false_negatives = historical_data[
        (historical_data['risk_score'] < 50) &
        (historical_data['actual_exploitation'] == True)
    ]

    # Calculate model accuracy
    accuracy_metrics = {
        'precision': calculate_precision(historical_data),
        'recall': calculate_recall(historical_data),
        'false_positive_rate': len(false_positives) / len(historical_data),
        'false_negative_rate': len(false_negatives) / len(historical_data)
    }

    # Generate optimization recommendations
    recommendations = []
    if accuracy_metrics['false_positive_rate'] > 0.15:
        recommendations.append("Consider reducing weight for CVSS score")
    if accuracy_metrics['false_negative_rate'] > 0.05:
        recommendations.append("Increase weight for EPSS and KEV status")

    return accuracy_metrics, recommendations
```

**Output:** Model optimization insights and recommendations

---

## Recommended CTI Products

### Primary Products
- **Tenable.io Lumin** - Vulnerability prioritization with Predictive Prioritization
  - Assessment: [Tenable](https://github.com/Masriyan/CTI-Product-Assesment-Matrix#tenable)
  - Key Features: Risk-based prioritization, VPR scores, asset criticality, exploit maturity

- **Rapid7 InsightVM** - Vulnerability risk assessment with Real Risk
  - Assessment: [Rapid7](https://github.com/Masriyan/CTI-Product-Assesment-Matrix#rapid7)
  - Key Features: Real Risk scoring, exploit availability, threat context, remediation projects

### Alternative/Complementary Products
- **Qualys VMDR** - Vulnerability management with TruRisk
  - Assessment: [Qualys](https://github.com/Masriyan/CTI-Product-Assesment-Matrix#qualys)

- **Recorded Future** - Threat intelligence for vulnerability prioritization
  - Assessment: [Recorded Future](https://github.com/Masriyan/CTI-Product-Assesment-Matrix#recorded-future)

- **Kenna Security (Cisco Vulnerability Management)** - Risk-based vulnerability management
  - Assessment: [Kenna Security](https://github.com/Masriyan/CTI-Product-Assesment-Matrix#kenna-security)

### Open Source Options
- **EPSS (Exploit Prediction Scoring System)** - Free exploitation probability scores
- **CISA KEV Catalog** - Known exploited vulnerabilities list
- **CVE/NVD APIs** - National Vulnerability Database
- **MISP** - Open-source threat intelligence platform

## Expected Outputs

### Deliverables
1. **Prioritized Remediation List**
   - Format: Excel spreadsheet, PDF report
   - Content: Ranked vulnerabilities with risk scores, SLAs, context
   - Audience: IT operations, patch management, asset owners

2. **Executive Dashboard**
   - Format: PowerBI/Tableau dashboard or PDF
   - Content: Key metrics, trends, high-risk areas, SLA compliance
   - Audience: CISO, security leadership, executives

3. **Remediation Tickets**
   - Format: ServiceNow/Jira tickets
   - Content: Detailed remediation instructions, business justification, SLA
   - Audience: IT operations, system administrators

4. **Threat Intelligence Report**
   - Format: PDF with intelligence context
   - Content: Exploitation trends, threat actor campaigns, emerging threats
   - Audience: CTI team, security operations, management

### Sample Output
```json
{
  "vulnerability_prioritization": {
    "analysis_date": "2025-12-30",
    "total_vulnerabilities": 15247,
    "prioritization_results": {
      "p1_critical": 89,
      "p2_high": 456,
      "p3_medium": 2341,
      "p4_low": 12361
    },
    "top_10_risks": [
      {
        "rank": 1,
        "cve": "CVE-2024-1234",
        "risk_score": 98,
        "cvss": 9.8,
        "in_cisa_kev": true,
        "epss_score": 0.89,
        "affected_assets": 47,
        "asset_criticality": "critical",
        "exposure": "external",
        "remediation_sla": "0-7 days",
        "threat_context": "Actively exploited by APT28, ransomware campaigns"
      }
    ],
    "exploitation_intelligence": {
      "cves_in_cisa_kev": 23,
      "cves_with_public_exploits": 187,
      "confirmed_exploitation_attempts": 12
    },
    "remediation_progress": {
      "remediated_last_30_days": 1247,
      "sla_compliance_rate": "87%",
      "avg_time_to_remediation_days": 23
    }
  }
}
```

## Success Metrics
- Prioritization accuracy: >85% of P1/P2 vulnerabilities validated as high-risk
- Remediation velocity: P1 vulnerabilities remediated within 7 days (>90%)
- Risk reduction: Measurable decrease in total risk score month-over-month
- False positive rate: <10% of high-priority vulnerabilities
- Stakeholder satisfaction: Positive feedback from IT operations on actionability

## Tips & Best Practices

### General Tips
- Don't rely solely on CVSS—it measures technical severity, not actual risk
- Integrate multiple intelligence sources for comprehensive view
- Update prioritization regularly as threat landscape changes
- Communicate business impact, not just technical details, to stakeholders
- Track remediation outcomes to validate and improve scoring model

### Common Pitfalls to Avoid
- **CVSS-only prioritization**: Leads to focusing on low-risk high-CVSS issues while missing actively exploited vulnerabilities
- **Ignoring asset context**: Same CVE on DMZ web server vs. internal print server has vastly different risk
- **Static prioritization**: Threat landscape changes daily; refresh intelligence continuously
- **Analysis paralysis**: Perfect scoring is impossible; aim for "good enough" and iterate

### Optimization Strategies
- Automate intelligence enrichment to scale analysis
- Build remediation difficulty into scoring (quick wins vs. complex changes)
- Create asset grouping to batch remediation efforts
- Use virtual patching (WAF rules) for buy-time on complex remediations
- Leverage threat intelligence platform integrations with vulnerability scanners

### Automation Opportunities
- Automated daily CVE enrichment with exploit intelligence
- SOAR workflows for ticket creation and assignment
- Real-time alerts for new CISA KEV entries affecting environment
- Automated SLA tracking and escalation
- Integration with patch management for automated deployment

## Real-World Application

### Industry Examples
- **Financial Services:** Bank reduces critical vulnerability backlog by 70% using risk-based prioritization
- **Healthcare:** Hospital system focuses on internet-facing vulnerabilities with active exploits, preventing ransomware
- **Technology:** SaaS provider integrates customer impact into prioritization for multi-tenant environments
- **Government:** Agency aligns with CISA BOD 22-01 mandate using KEV-based prioritization

### Case Study
A large retail organization struggled with 18,000 open vulnerabilities and limited patching resources:

**Challenge:**
- 18,427 total vulnerabilities across 5,000 assets
- IT team could patch ~500 vulnerabilities/month
- Traditional CVSS prioritization led to low-impact but high-CVSS patches
- Multiple security incidents from actively exploited but "medium" CVSS vulnerabilities

**Solution Implementation:**
1. Implemented risk-based scoring combining CVSS, EPSS, CISA KEV, and asset criticality
2. Identified 147 P1 critical vulnerabilities (vs. 4,200 "critical" by CVSS alone)
3. Focused remediation on P1/P2 tiers with clear SLAs
4. Automated daily intelligence updates and prioritization

**Results (6 months):**
- Remediated 98% of P1 vulnerabilities within 7-day SLA
- Reduced risk score by 64% despite total vulnerability count only decreasing by 15%
- Zero security incidents from vulnerabilities on prioritized list
- IT operations reported "finally have actionable, realistic remediation targets"
- Identified and blocked exploitation attempts on 8 high-priority CVEs before patches deployed

The key success factor was shifting from "patch everything" to "patch what matters most" using intelligence-driven prioritization.

## Additional Resources

### Documentation
- [CISA Known Exploited Vulnerabilities](https://www.cisa.gov/known-exploited-vulnerabilities-catalog)
- [EPSS Documentation](https://www.first.org/epss/)
- [CVSS Specification](https://www.first.org/cvss/)
- [NIST Vulnerability Management Guide](https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-40r4.pdf)

### Training Materials
- SANS SEC460: Enterprise Threat and Vulnerability Assessment
- "Risk-Based Vulnerability Management" webinars
- Vulnerability management certifications

### Community Resources
- FIRST (Forum of Incident Response and Security Teams)
- Twitter: #vulnerabilitymanagement, #CVE
- Reddit: r/netsec, r/cybersecurity
- Vulnerability management LinkedIn groups

## Related Use Cases
- [THD-UC007: Hunt for CVE Exploitation Attempts](../threat-hunting-detection/UC007-hunt-cve-exploitation-attempts.md) - Detecting exploitation
- [VI-UC002: Track Zero-Day Exploitation in the Wild](UC002-track-zero-day-exploitation-wild.md) - Emerging threats
- [VI-UC005: Correlate Vulnerabilities with Asset Inventory](UC005-correlate-vulnerabilities-asset-inventory.md) - Asset context

## Version History
| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | 2025-12-30 | CTI Team | Initial creation |
